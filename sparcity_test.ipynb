{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0337edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math, re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "sys.path.append('./')\n",
    "from models import EfficientKAN, FastKAN, BSRBF_KAN, FasterKAN, MLP, FC_KAN, WCSRBFKAN, WendlandCSRBF, RadialBasisFunction, WCSRBFKANSolo\n",
    "from torch.serialization import add_safe_globals\n",
    "add_safe_globals([\n",
    "    EfficientKAN, FastKAN, BSRBF_KAN, FasterKAN, MLP, FC_KAN, WCSRBFKAN, WCSRBFKANSolo, WendlandCSRBF, RadialBasisFunction\n",
    "])\n",
    "\n",
    "DISPLAY_DATASET = {\"mnist\": \"MNIST\", \"fashion_mnist\": \"Fashion-MNIST\"}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b50f7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def check_csrbf_sparsity_on_dataset(model_path,\n",
    "                                    dataset_name=\"MNIST\",     # \"MNIST\" or \"FashionMNIST\"\n",
    "                                    batch_size=256,\n",
    "                                    max_batches=None,         # None = all test batches\n",
    "                                    threshold=1e-8,           # tiny tol; W-CSRBF is truly zero outside support\n",
    "                                    ):\n",
    "    \"\"\"\n",
    "    Returns dict with overall averages:\n",
    "      - 'density'\n",
    "      - 'zero_fraction'\n",
    "      - 'avg_active_centers_per_sample_feature'\n",
    "    \"\"\"\n",
    "\n",
    "    model = torch.load(model_path, weights_only=False, map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    # print(model.device)\n",
    "\n",
    "    tfm = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,))])\n",
    "    name = dataset_name.strip().lower()\n",
    "    if name in (\"mnist\", \"mnist-test\"):\n",
    "        ds = datasets.MNIST(root=\"./data\", train=False, download=True, transform=tfm)\n",
    "    elif name in (\"fashionmnist\", \"fashion-mnist\", \"fashion\"):\n",
    "        ds = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=tfm)\n",
    "    else:\n",
    "        raise ValueError(\"dataset_name must be 'MNIST' or 'FashionMNIST'.\")\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    layers = getattr(model, \"layers\", None)\n",
    "    if layers is None and hasattr(model, \"module\"):\n",
    "        layers = getattr(model.module, \"layers\", None)\n",
    "    if layers is None:\n",
    "        raise RuntimeError(\"Model must expose .layers (ModuleList of W-CSRBF layers in order).\")\n",
    "\n",
    "    total_active = 0\n",
    "    total_elems  = 0\n",
    "    sum_active_per_sf = 0.0   # sum over (# active centers) per (sample, feature)\n",
    "    num_sf = 0                # total count of (sample, feature) pairs\n",
    "\n",
    "    for b_idx, (xb, _) in enumerate(loader):\n",
    "        if max_batches is not None and b_idx >= max_batches:\n",
    "            break\n",
    "        xb = xb.to(device)\n",
    "        if xb.dim() == 4:               # (B,1,28,28) -> (B,784)\n",
    "            xb = xb.view(xb.size(0), -1)\n",
    "        x_curr = xb\n",
    "\n",
    "        # walk through the network, measuring CSRBF φ at each CSRBF layer\n",
    "        for layer in layers:\n",
    "            # get the input to this layer in its own space (with LN if present)\n",
    "            z = x_curr\n",
    "            if hasattr(layer, \"layernorm\"):\n",
    "                z = layer.layernorm(z)\n",
    "\n",
    "            if hasattr(layer, \"csrbf\"):  # this is a W-CSRBF layer\n",
    "                # φ: (B, D*M) -> (B, D, M)\n",
    "                D = int(layer.csrbf.in_features)\n",
    "                M = int(layer.csrbf.n_centers)\n",
    "                phi = layer.csrbf(z).view(z.size(0), D, M)\n",
    "\n",
    "                mask = (phi.abs() > threshold)\n",
    "                total_active += int(mask.sum().item())\n",
    "                total_elems  += int(mask.numel())\n",
    "\n",
    "                active_per_sf = mask.sum(dim=2).float()   # (B, D)\n",
    "                sum_active_per_sf += float(active_per_sf.sum().item())\n",
    "                num_sf += int(active_per_sf.numel())\n",
    "\n",
    "            elif hasattr(layer, \"rbf\"):  # this is a FastKANLayer with Gaussian RBFs\n",
    "                # 'z' is already the layer's input in its own space (you applied layer.layernorm above)\n",
    "                # FastKANLayer.forward does: rbf(layernorm(x)), so use the same here:\n",
    "                phi = layer.rbf(z)                     # (B, D, M)\n",
    "                B, D, M = phi.shape                    # D = z.size(1), M = layer.rbf.grid.numel()\n",
    "\n",
    "                mask = (phi.abs() > threshold)         # for Gaussians, this is a \"near-zero\" cutoff\n",
    "                total_active += int(mask.sum().item())\n",
    "                total_elems  += int(mask.numel())\n",
    "\n",
    "                active_per_sf = mask.sum(dim=2).float()  # (B, D)\n",
    "                sum_active_per_sf += float(active_per_sf.sum().item())\n",
    "                num_sf += int(active_per_sf.numel())\n",
    "\n",
    "\n",
    "            # propagate to the next layer's input\n",
    "            x_curr = layer(x_curr)\n",
    "\n",
    "    if total_elems == 0 or num_sf == 0:\n",
    "        raise RuntimeError(\"No CSRBF features were found/processed. Check that your model has CSRBF layers.\")\n",
    "\n",
    "    density = total_active / float(total_elems)\n",
    "    zero_fraction = 1.0 - density\n",
    "    avg_active_centers = sum_active_per_sf / float(num_sf)\n",
    "\n",
    "    return {\n",
    "        \"density\": density,\n",
    "        \"zero_fraction\": zero_fraction,\n",
    "        \"avg_active_centers_per_sample_feature\": avg_active_centers,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9e7a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This code picks json files from folder which contain the model training and epoch metrics\n",
    "Then extracts the best epoch out of how much ever training run you have done\n",
    "displays the best and average metrics as a table \n",
    "and return the details of the best epochs with the best epoch model file name and path\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def canon_dataset(name: str) -> str:\n",
    "    s = name.strip().lower().replace(\"-\", \"_\")\n",
    "    if s in {\"fashionmnist\", \"fashion__mnist\", \"fashion_mnist\"}:\n",
    "        return \"fashion_mnist\"\n",
    "    return s\n",
    "\n",
    "def find_run_idx(path: Path) -> int | None:\n",
    "    \"\"\"Return the nearest parent named output<digits>.\"\"\"\n",
    "    for p in [path] + list(path.parents):\n",
    "        m = re.fullmatch(r\"output(\\d+)\", p.name, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "def scan_files(root: Path) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Find files like: output*/<dataset>/<model>/<model>__<dataset>__full.json\n",
    "    Return: dict(run, dataset, model, path, json_name)\n",
    "    \"\"\"\n",
    "    files = list(root.glob(\"output*/**/*__*__full.json\"))\n",
    "    rows = []\n",
    "    for fp in files:\n",
    "        m = re.fullmatch(r\"(.+?)__([^_].+?)__full\\.json\", fp.name, flags=re.IGNORECASE)\n",
    "        if not m:\n",
    "            continue\n",
    "        model = m.group(1).strip().lower()\n",
    "        dataset = canon_dataset(m.group(2))\n",
    "        run = find_run_idx(fp)\n",
    "        if run is None:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"run\": run,\n",
    "            \"dataset\": dataset,\n",
    "            \"model\": model,\n",
    "            \"path\": fp.resolve(),\n",
    "            \"json_name\": fp.name,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def load_json_any(path: Path) -> tuple[pd.DataFrame, float]:\n",
    "    \"\"\"Load JSONL (epochs + optional final {'training time': ...}) or JSON array.\"\"\"\n",
    "    try:\n",
    "        df_all = pd.read_json(path, lines=True)\n",
    "    except ValueError:\n",
    "        with open(path, \"r\") as f:\n",
    "            obj = json.load(f)\n",
    "        df_all = pd.DataFrame(obj)\n",
    "\n",
    "    ttime = pd.to_numeric(df_all.get(\"training time\"), errors=\"coerce\").dropna()\n",
    "    ttime = float(ttime.iloc[0]) if not ttime.empty else np.nan\n",
    "\n",
    "    if \"epoch\" not in df_all.columns:\n",
    "        return pd.DataFrame(), ttime\n",
    "    df = (df_all.dropna(subset=[\"val_accuracy\"])\n",
    "                 .sort_values(\"val_accuracy\", ascending=False)\n",
    "                 .reset_index(drop=True))\n",
    "    return df, ttime\n",
    "\n",
    "def percent(x: pd.Series) -> pd.Series:\n",
    "    return (x * 100).round(2)\n",
    "\n",
    "def build_display_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if \"dataset\" in out:\n",
    "        out[\"Dataset\"] = out[\"dataset\"].map(DISPLAY_DATASET).fillna(out[\"dataset\"])\n",
    "    if \"model\" in out:\n",
    "        out[\"#Params\"] = out[\"model\"].map(PARAMS).astype(\"Int64\")\n",
    "    if \"train_acc\" in out: out[\"Train. Acc.\"] = percent(out[\"train_acc\"])\n",
    "    if \"val_acc\" in out: out[\"Val. Acc.\"]= percent(out[\"val_acc\"])\n",
    "    if \"f1\" in out: out[\"F1\"] = percent(out[\"f1\"])\n",
    "    if \"precision\" in out: out[\"precision\"] = percent(out[\"precision\"])\n",
    "    if \"recall\" in out: out[\"recall\"] = percent(out[\"recall\"])\n",
    "    if \"time_sec\"  in out: out[\"Time (sec)\"]  = out[\"time_sec\"].round(1)\n",
    "    cols = [\"Dataset\",\"model\",\"Train. Acc.\",\"Val. Acc.\",\"F1\",\"precision\",\"recall\",\"Time (sec)\",\"#Params\",\n",
    "            \"run\",\"final_epoch\",\"json_name\",\"path\"]\n",
    "    return out[[c for c in cols if c in out.columns]]\n",
    "\n",
    "def table(ROOT):\n",
    "    records = scan_files(ROOT)\n",
    "    if not records:\n",
    "        raise SystemExit(\"No matching files found (output*/**/*__*__full.json).\")\n",
    "\n",
    "    final_rows = []\n",
    "\n",
    "    for rec in records:\n",
    "        df, ttime = load_json_any(rec[\"path\"])\n",
    "        if df.empty or \"val_accuracy\" not in df or \"train_accuracy\" not in df:\n",
    "            continue\n",
    "\n",
    "        final = df.loc[df[\"val_accuracy\"].idxmax()]\n",
    "        final_rows.append({\n",
    "            \"run\": rec[\"run\"],\n",
    "            \"dataset\": rec[\"dataset\"],\n",
    "            \"model\": rec[\"model\"],\n",
    "            \"final_epoch\": int(final[\"epoch\"]),\n",
    "            \"val_acc\": float(final[\"val_accuracy\"]),\n",
    "            \"train_acc\": float(final[\"train_accuracy\"]),\n",
    "            \"f1\": float(final.get(\"f1_macro\", np.nan)),\n",
    "            \"precision\": float(final.get(\"pre_macro\", np.nan)),\n",
    "            \"recall\": float(final.get(\"re_macro\", np.nan)),\n",
    "            \"time_sec\": float(ttime),\n",
    "            \"json_name\": rec[\"json_name\"],\n",
    "            \"path\": str(rec[\"path\"]),\n",
    "        })\n",
    "\n",
    "    final_df = pd.DataFrame(final_rows)\n",
    "    if final_df.empty:\n",
    "        raise SystemExit(\"No usable results (missing epoch/accuracy columns).\")\n",
    "\n",
    "    best_final = (\n",
    "        final_df\n",
    "        .sort_values(\n",
    "            by=[\"dataset\",\"model\",\"val_acc\"],\n",
    "            ascending=[True, True, False]\n",
    "        )\n",
    "        .groupby([\"dataset\",\"model\"], as_index=False)\n",
    "        .head(1)\n",
    "    )\n",
    "\n",
    "    best_table = build_display_table(best_final.sort_values(by=[\"val_acc\"],ascending=[False]))\n",
    "    print(\"Best metrics per dataset/model (best epoch by Val. Acc)\")\n",
    "    print(best_table.to_string(index=False))\n",
    "\n",
    "    avg_per_dataset = (\n",
    "        final_df\n",
    "        .groupby([\"dataset\",\"model\"], as_index=False)\n",
    "        .agg(train_acc=(\"train_acc\",\"mean\"),\n",
    "            val_acc=(\"val_acc\",\"mean\"),\n",
    "            f1=(\"f1\",\"mean\"),\n",
    "            time_sec=(\"time_sec\",\"mean\"))\n",
    "    )\n",
    "    avg_table = build_display_table(avg_per_dataset.sort_values(by=[\"val_acc\"],ascending=[False]))\n",
    "    print(\"\\nAverage metrics across runs (mean of best epoch by Val. Acc for 3 indipendent training runs) per dataset/model\")\n",
    "    print(avg_table.to_string(index=False))\n",
    "\n",
    "    return best_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07bffa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_paths_dict(result):\n",
    "    best_model_path = dict()\n",
    "    for i, r in result.loc[:,[\"model\",\"path\"]].iterrows():\n",
    "        path_list = r[\"path\"].split(\"/\")\n",
    "        json_to_pth = path_list[-1].split(\".\")[0]+\".pth\"\n",
    "        best_model_path[r[\"model\"]] = \"./\"+\"/\".join(path_list[8:-1])+f\"/{json_to_pth}\"\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afdefba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best metrics per dataset/model (best epoch by Val. Acc)\n",
      "      Dataset           model  Train. Acc.  Val. Acc.    F1  precision  recall  Time (sec)  #Params  run  final_epoch                                 json_name                                                                                                                                         path\n",
      "        MNIST          fc_kan        99.45      97.66 97.62      97.62   97.62       210.2   558979    2           15                  fc_kan__mnist__full.json                                   /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output2/mnist/fc_kan/fc_kan__mnist__full.json\n",
      "        MNIST             mlp        97.52      97.14 97.11      97.12   97.10       119.5    50816    3           15                     mlp__mnist__full.json                                         /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/mnist/mlp/mlp__mnist__full.json\n",
      "        MNIST   wcsrbf_kan_un        97.74      96.42 96.37      96.38   96.37       148.8   457492    2           14           wcsrbf_kan_un__mnist__full.json                     /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output2/mnist/wcsrbf_kan_un/wcsrbf_kan_un__mnist__full.json\n",
      "        MNIST        fast_kan        97.61      96.42 96.37      96.38   96.37       130.4   457418    1           15                fast_kan__mnist__full.json                               /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output1/mnist/fast_kan/fast_kan__mnist__full.json\n",
      "        MNIST       bsrbf_kan        97.99      96.25 96.19      96.22   96.18       160.4   457344    3           15               bsrbf_kan__mnist__full.json                             /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/mnist/bsrbf_kan/bsrbf_kan__mnist__full.json\n",
      "        MNIST   efficient_kan        96.12      95.91 95.85      95.86   95.85       155.9   508160    3           15           efficient_kan__mnist__full.json                     /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/mnist/efficient_kan/efficient_kan__mnist__full.json\n",
      "        MNIST wcsrbf_kan_solo        98.61      94.97 94.89      94.92   94.88       130.9   406602    3           15         wcsrbf_kan_solo__mnist__full.json                 /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/mnist/wcsrbf_kan_solo/wcsrbf_kan_solo__mnist__full.json\n",
      "        MNIST      faster_kan        91.73      92.38 92.21      92.24   92.21       121.9   406528    3           15              faster_kan__mnist__full.json                           /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/mnist/faster_kan/faster_kan__mnist__full.json\n",
      "Fashion-MNIST          fc_kan        94.60      89.30 89.21      89.21   89.25       337.1   558979    2           23          fc_kan__fashion_mnist__full.json                   /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output2/fashion_mnist/fc_kan/fc_kan__fashion_mnist__full.json\n",
      "Fashion-MNIST       bsrbf_kan        93.03      88.24 88.11      88.10   88.18       255.9   457344    3           25       bsrbf_kan__fashion_mnist__full.json             /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/fashion_mnist/bsrbf_kan/bsrbf_kan__fashion_mnist__full.json\n",
      "Fashion-MNIST        fast_kan        91.85      88.08 87.96      87.95   88.02       229.1   457418    1           25        fast_kan__fashion_mnist__full.json               /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output1/fashion_mnist/fast_kan/fast_kan__fashion_mnist__full.json\n",
      "Fashion-MNIST             mlp        89.70      87.54 87.45      87.44   87.48       196.7    50816    3           24             mlp__fashion_mnist__full.json                         /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output3/fashion_mnist/mlp/mlp__fashion_mnist__full.json\n",
      "Fashion-MNIST   wcsrbf_kan_un        92.88      86.74 86.61      86.58   86.68       235.2   457492    1           25   wcsrbf_kan_un__fashion_mnist__full.json     /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output1/fashion_mnist/wcsrbf_kan_un/wcsrbf_kan_un__fashion_mnist__full.json\n",
      "Fashion-MNIST      faster_kan        87.77      85.47 85.33      85.34   85.43       210.9   406528    1           24      faster_kan__fashion_mnist__full.json           /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output1/fashion_mnist/faster_kan/faster_kan__fashion_mnist__full.json\n",
      "Fashion-MNIST wcsrbf_kan_solo        93.27      85.41 85.34      85.33   85.40       218.0   406602    2           25 wcsrbf_kan_solo__fashion_mnist__full.json /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output2/fashion_mnist/wcsrbf_kan_solo/wcsrbf_kan_solo__fashion_mnist__full.json\n",
      "Fashion-MNIST   efficient_kan        87.09      85.10 84.97      84.93   85.09       262.5   508160    2           25   efficient_kan__fashion_mnist__full.json     /mnt/c/Users/aravi/OneDrive/Desktop/Thesis/output_without_ln/output2/fashion_mnist/efficient_kan/efficient_kan__fashion_mnist__full.json\n",
      "\n",
      "Average metrics across runs (mean of best epoch by Val. Acc for 3 indipendent training runs) per dataset/model\n",
      "      Dataset           model  Train. Acc.  Val. Acc.    F1  Time (sec)  #Params\n",
      "        MNIST          fc_kan        99.46      97.53 97.49       215.6   558979\n",
      "        MNIST             mlp        97.54      97.08 97.05       121.2    50816\n",
      "        MNIST        fast_kan        97.36      96.24 96.19       133.9   457418\n",
      "        MNIST       bsrbf_kan        97.84      96.20 96.14       158.9   457344\n",
      "        MNIST   wcsrbf_kan_un        97.57      96.18 96.13       145.4   457492\n",
      "        MNIST   efficient_kan        96.12      95.84 95.78       160.6   508160\n",
      "        MNIST wcsrbf_kan_solo        98.55      94.76 94.67       136.3   406602\n",
      "        MNIST      faster_kan        91.57      92.00 91.85       124.5   406528\n",
      "Fashion-MNIST          fc_kan        94.48      89.21 89.13       348.9   558979\n",
      "Fashion-MNIST       bsrbf_kan        93.00      88.21 88.08       257.2   457344\n",
      "Fashion-MNIST        fast_kan        91.73      87.91 87.80       226.9   457418\n",
      "Fashion-MNIST             mlp        89.72      87.45 87.33       194.2    50816\n",
      "Fashion-MNIST   wcsrbf_kan_un        92.86      86.63 86.51       244.3   457492\n",
      "Fashion-MNIST wcsrbf_kan_solo        93.25      85.28 85.17       232.2   406602\n",
      "Fashion-MNIST      faster_kan        87.56      85.19 85.03       207.7   406528\n",
      "Fashion-MNIST   efficient_kan        87.00      84.91 84.77       265.7   508160\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {\n",
    "    \"bsrbf_kan\": 457344,\n",
    "    \"fast_kan\": 457418,\n",
    "    \"faster_kan\": 406528,\n",
    "    \"efficient_kan\": 508160,\n",
    "    \"wcsrbf_kan_un\": 457492,\n",
    "    \"wcsrbf_kan_solo\": 406602,\n",
    "    \"mlp\": 50816,\n",
    "    \"fc_kan\": 558979\n",
    "}\n",
    "\n",
    "root= Path(f\"{os.getcwd()}/output_without_ln\")\n",
    "btable = table(ROOT=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f747bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fc_kan': './output_without_ln/output2/fashion_mnist/fc_kan/fc_kan__fashion_mnist__full.pth', 'bsrbf_kan': './output_without_ln/output3/fashion_mnist/bsrbf_kan/bsrbf_kan__fashion_mnist__full.pth', 'fast_kan': './output_without_ln/output1/fashion_mnist/fast_kan/fast_kan__fashion_mnist__full.pth', 'mlp': './output_without_ln/output3/fashion_mnist/mlp/mlp__fashion_mnist__full.pth', 'wcsrbf_kan_un': './output_without_ln/output1/fashion_mnist/wcsrbf_kan_un/wcsrbf_kan_un__fashion_mnist__full.pth', 'faster_kan': './output_without_ln/output1/fashion_mnist/faster_kan/faster_kan__fashion_mnist__full.pth', 'wcsrbf_kan_solo': './output_without_ln/output2/fashion_mnist/wcsrbf_kan_solo/wcsrbf_kan_solo__fashion_mnist__full.pth', 'efficient_kan': './output_without_ln/output2/fashion_mnist/efficient_kan/efficient_kan__fashion_mnist__full.pth'}\n"
     ]
    }
   ],
   "source": [
    "result_mnist = btable.query(\"Dataset=='Fashion-MNIST'\")\n",
    "best_model_path_mnist = get_best_model_paths_dict(result_mnist)\n",
    "print(best_model_path_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4605c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_kan: {'density': 0.876907797759434, 'zero_fraction': 0.12309220224056605, 'avg_active_centers_per_sample_feature': 7.015262382075472}\n",
      "wcsrbf_kan_un: {'density': 0.24408677771226414, 'zero_fraction': 0.7559132222877358, 'avg_active_centers_per_sample_feature': 1.9526942216981131}\n",
      "wcsrbf_kan_solo: {'density': 0.24572326061320754, 'zero_fraction': 0.7542767393867924, 'avg_active_centers_per_sample_feature': 1.9657860849056603}\n"
     ]
    }
   ],
   "source": [
    "models_list = [\"fast_kan\", \"wcsrbf_kan_un\", \"wcsrbf_kan_solo\" ]\n",
    "\n",
    "for model_name in models_list:\n",
    "    path = best_model_path_mnist[model_name]\n",
    "    stats_kan_base = check_csrbf_sparsity_on_dataset(\n",
    "        model_path=path,\n",
    "        dataset_name=\"Fashion-MNIST\",\n",
    "        batch_size=256,\n",
    "        max_batches=None,   \n",
    "        threshold=1e-8     \n",
    "    )\n",
    "\n",
    "    print(f\"{model_name}: {stats_kan_base}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"wcsrbf_kan_un\": 457492,\n",
    "    \"wcsrbf_kan_tc_un\": 464276,\n",
    "    \"wcsrbf_kan_ts_un\": 464276,\n",
    "    \"wcsrbf_kan_tc_ts_un\": 471060,\n",
    "    \"wcsrbf_kan_solo\": 406602,\n",
    "    \"wcsrbf_kan_solo_tc\": 413386,\n",
    "    \"wcsrbf_kan_solo_ts\": 413386,\n",
    "    \"wcsrbf_kan_solo_tc_ts\": 420170,\n",
    "}\n",
    "\n",
    "root = Path(f\"{os.getcwd()}/wcsrbf_op\")\n",
    "btable_wcsrbf = table(ROOT=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f0b21bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wcsrbf_kan_tc_ts_un': './wcsrbf_op/output1/fashion_mnist/wcsrbf_kan_tc_ts_un/wcsrbf_kan_tc_ts_un__fashion_mnist__full.pth', 'wcsrbf_kan_ts_un': './wcsrbf_op/output3/fashion_mnist/wcsrbf_kan_ts_un/wcsrbf_kan_ts_un__fashion_mnist__full.pth', 'wcsrbf_kan_solo_tc_ts': './wcsrbf_op/output2/fashion_mnist/wcsrbf_kan_solo_tc_ts/wcsrbf_kan_solo_tc_ts__fashion_mnist__full.pth', 'wcsrbf_kan_solo_ts': './wcsrbf_op/output2/fashion_mnist/wcsrbf_kan_solo_ts/wcsrbf_kan_solo_ts__fashion_mnist__full.pth', 'wcsrbf_kan_tc_un': './wcsrbf_op/output1/fashion_mnist/wcsrbf_kan_tc_un/wcsrbf_kan_tc_un__fashion_mnist__full.pth', 'wcsrbf_kan_solo_tc': './wcsrbf_op/output2/fashion_mnist/wcsrbf_kan_solo_tc/wcsrbf_kan_solo_tc__fashion_mnist__full.pth', 'wcsrbf_kan_un': './wcsrbf_op/output1/fashion_mnist/wcsrbf_kan_un/wcsrbf_kan_un__fashion_mnist__full.pth', 'wcsrbf_kan_solo': './wcsrbf_op/output2/fashion_mnist/wcsrbf_kan_solo/wcsrbf_kan_solo__fashion_mnist__full.pth'}\n"
     ]
    }
   ],
   "source": [
    "result_mnist_wcsrbf = btable_wcsrbf.query(\"Dataset=='Fashion-MNIST'\")\n",
    "best_model_path_mnist_wcsrbf = get_best_model_paths_dict(result_mnist_wcsrbf)\n",
    "\n",
    "print(best_model_path_mnist_wcsrbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b07f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wcsrbf_kan_tc_un: {'density': 0.2503430571933962, 'zero_fraction': 0.7496569428066038, 'avg_active_centers_per_sample_feature': 2.00274445754717}\n",
      "wcsrbf_kan_solo_tc: {'density': 0.24938012971698112, 'zero_fraction': 0.7506198702830189, 'avg_active_centers_per_sample_feature': 1.995041037735849}\n"
     ]
    }
   ],
   "source": [
    "models_list = [\"wcsrbf_kan_tc_un\", \"wcsrbf_kan_solo_tc\" ]\n",
    "\n",
    "for model_name in models_list:\n",
    "    path = best_model_path_mnist_wcsrbf[model_name]\n",
    "    stats_kan_base = check_csrbf_sparsity_on_dataset(\n",
    "        model_path=path,\n",
    "        dataset_name=\"Fashion-MNIST\",\n",
    "        batch_size=256,\n",
    "        max_batches=None,   \n",
    "        threshold=1e-8     \n",
    "    )\n",
    "\n",
    "    print(f\"{model_name}: {stats_kan_base}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02cef5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wcsrbf_kan_ts_un: {'density': 0.9831933372641509, 'zero_fraction': 0.016806662735849076, 'avg_active_centers_per_sample_feature': 7.865546698113207}\n",
      "wcsrbf_kan_solo_ts: {'density': 0.9459000884433962, 'zero_fraction': 0.054099911556603764, 'avg_active_centers_per_sample_feature': 7.56720070754717}\n"
     ]
    }
   ],
   "source": [
    "models_list = [\"wcsrbf_kan_ts_un\", \"wcsrbf_kan_solo_ts\" ]\n",
    "\n",
    "for model_name in models_list:\n",
    "    path = best_model_path_mnist_wcsrbf[model_name]\n",
    "    stats_kan_base = check_csrbf_sparsity_on_dataset(\n",
    "        model_path=path,\n",
    "        dataset_name=\"Fashion-MNIST\",\n",
    "        batch_size=256,\n",
    "        max_batches=None,   \n",
    "        threshold=1e-8     \n",
    "    )\n",
    "\n",
    "    print(f\"{model_name}: {stats_kan_base}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2169dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wcsrbf_kan_tc_ts_un: {'density': 0.9602665536556604, 'zero_fraction': 0.03973344634433962, 'avg_active_centers_per_sample_feature': 7.682132429245283}\n",
      "wcsrbf_kan_solo_tc_ts: {'density': 0.9084645194575471, 'zero_fraction': 0.09153548054245286, 'avg_active_centers_per_sample_feature': 7.267716155660377}\n"
     ]
    }
   ],
   "source": [
    "models_list = [\"wcsrbf_kan_tc_ts_un\", \"wcsrbf_kan_solo_tc_ts\" ]\n",
    "\n",
    "for model_name in models_list:\n",
    "    path = best_model_path_mnist_wcsrbf[model_name]\n",
    "    stats_kan_base = check_csrbf_sparsity_on_dataset(\n",
    "        model_path=path,\n",
    "        dataset_name=\"Fashion-MNIST\",\n",
    "        batch_size=256,\n",
    "        max_batches=None,   \n",
    "        threshold=1e-8     \n",
    "    )\n",
    "\n",
    "    print(f\"{model_name}: {stats_kan_base}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69bc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
